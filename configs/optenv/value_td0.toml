[config]
save_dir="results/optenv_value/"
exp_file="experiment/experiment.jl"
exp_module_name = "Main"
exp_func_name = "run_experiment"
pre_exp_files = ["experiment/random_optenv_data.jl"]
arg_iter_type = "iter"
post_exp = "gen_metric_dict"

[static_args]
init_num_episodes = 100
init_policy = "default"
num_episodes = 4000
num_grad_steps = 1
num_env_steps = 2
batch_size = 128
max_num_episodes = 100
max_episode_length = 200
history_window = 1
BufferType = "TransitionReplayBuffer"
hidden_size = 128
activation = "relu"
num_layers = 0
gamma = 0.99
optimizer = "ADAM"
replan = 0
bootstrap = true
curriculum = false
overlap = true
shaping = false
force = "offline"
gpu = true
corruption_rate = 0.0
drop_rate = 0.0
reg = false
continuing = false
AgentType = "MCValue"
recurrent_action_dim = 0
update_freq = 100
predict_window = 0
behavior = "default"
run_traj = false
measurement_funcs = """
        # online_returns,
        buffer_loss,
        estimate_startvalue,
        estimate_termvalue,
        mc_buffer_loss,
        # rollout_returns,
        # rollout_returns_wide,
        # rollout_returns_narrow,
        # rollout_returns_tanh,
        # rollout_returns_eval_env,
        # rollout_returns_constant,
        # action_gap,
"""

[sweep_args]
# lr = "[0.001, 0.0005, 0.0001]"
lr = "[0.0005]"
seed = "using Random; rand(MersenneTwister(4949215), 1:10^10, 30)"
state_representation = ["PVN_20", "PD-xy_128", "PD-0_128", "PD-x_128", "PD-xy_128", "parameters"]
EnvType = ["OptEnv-NoLP-syntheticCluster-SGD"]
pooling_func = ["mean"]
